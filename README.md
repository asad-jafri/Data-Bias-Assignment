# Data-Bias-Assignment

# I chose a threshold for this assignment of 0.5. I chose this threshold because being the midway point between the lowest score of 0.0 and the highest score of 1.0, I felt that it would be the most applicable threshold score. The label I chose was examining the "toxic" label in relation to each tweet. I felt this label was the most relevant to the purpose of this assignment.

# Before starting the data collection, my hypothesis was that the score given to each tweet would increase by a 3x multiple if the tweet was repeated three times. I thought this would occur because I thought that multiplying the tweet by 3 would, logically, multiply the score. I assumed that the score and tweet string were directly correlated. My "N" was 24. Although it was not a relatively high N value, I felt that it was high enough to give a good indication of how the rest of the dataset would be impacted by the data manipulation. 

# The results of the data were not what I expected. The result of repeating the tweet string by 3 led to a the score randomly increasing or decreasing, depending on the tweet itself. In some cases, repeating the tweet three times increased the score, and in other cases, it decreased the score. It revealed, through the data, that the score and the amount of words in the tweet, if repeated, had no direct relationship. This suprised me because I had expected all the scores to increase due to the tweets having more words. I thought that more words equaled a higher score. A theory I have is that the new data showed that the algorithm used to determine the score was based on a variable unrelated to the amount of words in the tweet. The score may have been based on a seperate variable such as obscene language. I hope to learn what the algorithm actually used to detect hateful language and predict a score.

# The results of the test showcased that there would be statistical parity in the data. I think that the sample N I chose would represent the entire dataset if multiplied by 3x. I knew this was likely true because when I tested the data through a small N value, such as 7, it had the same random result as with an N of 24 - no correlational relationship.

# The biases that may exist in this dataset is biased sampling. To me, it seemed that the data collection was random and did not seem to have any bias. Each tweet seemed random and did not have a certain, handpicked set of words in each tweet. However, since there was no relationship in the data between the original tweet and the multiplied tweet, there seemed to be biased sampling. I had thought that a very "hateful" or "obscene" tweet's score would increase if the amount of "hateful" words increased. This was not the case, as if a tweet with multiple curse words was multiplied, the user would have no idea whether the score would increase or decrease - it was random. I felt that this is biased sampling, as some types of data (any random tweet from the dataset) are systemically likely to be selected in a sample over others - we just have no idea which one is higher or lower. Correlation, to me, would be more indicative of an unbiased algorithm.
